{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 숙제()\n",
    "# - iris.csv 데이터를 로딩한 다음\n",
    "# - qnsfb망을 구성하시요\n",
    "# - parameter tuning을 구현하시요(pipeline 사용도 함께)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('iris.csv', header=None)\n",
    "dataset = dataframe.values\n",
    "X = dataset[1:,0:4].astype(float)\n",
    "y = dataset[1:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_y = encoder.transform(y)\n",
    "\n",
    "Y = np_utils.to_categorical(encoded_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=4, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp',KerasClassifier(build_fn=baseline_model,verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "# kfold = KFold(n_splits=10, shuffle=True)\n",
    "# results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "# print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ICT01_18\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ICT01_18\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "0.74667, (0.09798) with : {'mlp__batch_size': 5, 'mlp__epochs': 10}\n",
      "0.91333, (0.06700) with : {'mlp__batch_size': 5, 'mlp__epochs': 50}\n",
      "0.96000, (0.04422) with : {'mlp__batch_size': 5, 'mlp__epochs': 100}\n",
      "0.96000, (0.04422) with : {'mlp__batch_size': 5, 'mlp__epochs': 150}\n",
      "0.96000, (0.04422) with : {'mlp__batch_size': 5, 'mlp__epochs': 200}\n",
      "0.96667, (0.04472) with : {'mlp__batch_size': 5, 'mlp__epochs': 250}\n",
      "0.71333, (0.14314) with : {'mlp__batch_size': 10, 'mlp__epochs': 10}\n",
      "0.90000, (0.07454) with : {'mlp__batch_size': 10, 'mlp__epochs': 50}\n",
      "0.95333, (0.04269) with : {'mlp__batch_size': 10, 'mlp__epochs': 100}\n",
      "0.95333, (0.04269) with : {'mlp__batch_size': 10, 'mlp__epochs': 150}\n",
      "0.96000, (0.04422) with : {'mlp__batch_size': 10, 'mlp__epochs': 200}\n",
      "0.96667, (0.03333) with : {'mlp__batch_size': 10, 'mlp__epochs': 250}\n",
      "0.50667, (0.19137) with : {'mlp__batch_size': 20, 'mlp__epochs': 10}\n",
      "0.82667, (0.13400) with : {'mlp__batch_size': 20, 'mlp__epochs': 50}\n",
      "0.90000, (0.06146) with : {'mlp__batch_size': 20, 'mlp__epochs': 100}\n",
      "0.93333, (0.05963) with : {'mlp__batch_size': 20, 'mlp__epochs': 150}\n",
      "0.96000, (0.04422) with : {'mlp__batch_size': 20, 'mlp__epochs': 200}\n",
      "0.96000, (0.04422) with : {'mlp__batch_size': 20, 'mlp__epochs': 250}\n",
      "0.38667, (0.27293) with : {'mlp__batch_size': 40, 'mlp__epochs': 10}\n",
      "0.70000, (0.12383) with : {'mlp__batch_size': 40, 'mlp__epochs': 50}\n",
      "0.85333, (0.08327) with : {'mlp__batch_size': 40, 'mlp__epochs': 100}\n",
      "0.90000, (0.07454) with : {'mlp__batch_size': 40, 'mlp__epochs': 150}\n",
      "0.91333, (0.06700) with : {'mlp__batch_size': 40, 'mlp__epochs': 200}\n",
      "0.95333, (0.04269) with : {'mlp__batch_size': 40, 'mlp__epochs': 250}\n",
      "0.30000, (0.15846) with : {'mlp__batch_size': 60, 'mlp__epochs': 10}\n",
      "0.74000, (0.13149) with : {'mlp__batch_size': 60, 'mlp__epochs': 50}\n",
      "0.86000, (0.07572) with : {'mlp__batch_size': 60, 'mlp__epochs': 100}\n",
      "0.86000, (0.06289) with : {'mlp__batch_size': 60, 'mlp__epochs': 150}\n",
      "0.91333, (0.06000) with : {'mlp__batch_size': 60, 'mlp__epochs': 200}\n",
      "0.94000, (0.04667) with : {'mlp__batch_size': 60, 'mlp__epochs': 250}\n",
      "0.28000, (0.13920) with : {'mlp__batch_size': 80, 'mlp__epochs': 10}\n",
      "0.71333, (0.13679) with : {'mlp__batch_size': 80, 'mlp__epochs': 50}\n",
      "0.78667, (0.09798) with : {'mlp__batch_size': 80, 'mlp__epochs': 100}\n",
      "0.85333, (0.07775) with : {'mlp__batch_size': 80, 'mlp__epochs': 150}\n",
      "0.88000, (0.06532) with : {'mlp__batch_size': 80, 'mlp__epochs': 200}\n",
      "0.89333, (0.08537) with : {'mlp__batch_size': 80, 'mlp__epochs': 250}\n",
      "0.37333, (0.14967) with : {'mlp__batch_size': 100, 'mlp__epochs': 10}\n",
      "0.64000, (0.14360) with : {'mlp__batch_size': 100, 'mlp__epochs': 50}\n",
      "0.84000, (0.06799) with : {'mlp__batch_size': 100, 'mlp__epochs': 100}\n",
      "0.83333, (0.09545) with : {'mlp__batch_size': 100, 'mlp__epochs': 150}\n",
      "0.86000, (0.07572) with : {'mlp__batch_size': 100, 'mlp__epochs': 200}\n",
      "0.90000, (0.08563) with : {'mlp__batch_size': 100, 'mlp__epochs': 250}\n",
      "최적 스코어 : 0.9666666686534882, 사용한 파라미터 조합 : {'mlp__batch_size': 5, 'mlp__epochs': 250}\n"
     ]
    }
   ],
   "source": [
    "batch_size = [5,10,20,40,60,80,100]\n",
    "epochs=[10,50,100, 150, 200,250]\n",
    "param_grid = {'mlp__batch_size' : batch_size, 'mlp__epochs':epochs}\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "# results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "\n",
    "grid = GridSearchCV(estimator=pipeline, param_grid=param_grid,n_jobs=-1, cv=kfold)\n",
    "grid_result = grid.fit(X,Y)\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print('{:.5f}, ({:.5f}) with : {}'.format(mean, stdev, param))\n",
    "    \n",
    "print('최적 스코어 : {}, 사용한 파라미터 조합 : {}'.format(grid_result.best_score_,grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 0, 0, 0, 0, 2, 1, 0, 1, 1, 0, 0, 2, 1, 2, 2, 2, 0, 2, 2,\n",
       "       0, 1, 2, 0, 1, 2, 1, 2, 1, 1, 1, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 0,\n",
       "       0, 2, 0, 2, 0, 2, 0, 1, 1, 0, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2,\n",
       "       0, 2, 2, 0, 0, 1, 0, 2, 2, 0, 1, 1, 1, 2, 0, 1, 1, 1, 2, 0, 1, 1,\n",
       "       2, 0, 2, 1, 0, 0, 2, 0, 0, 2, 2, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       2, 1, 0, 2, 0, 1, 1, 0, 0, 1, 1, 2, 0, 1, 1, 1, 0, 1, 1, 2, 2, 0,\n",
       "       2, 1, 1, 0, 1, 0, 0, 2, 0, 1, 2, 1, 1, 1, 0, 1, 2, 1])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('iris.csv', header=None)\n",
    "dataset = dataframe.values\n",
    "X = dataset[1:,0:4].astype(float)\n",
    "y = dataset[1:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_y = encoder.transform(y)\n",
    "\n",
    "Y = np_utils.to_categorical(encoded_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=4, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp',KerasClassifier(build_fn=baseline_model,verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "# kfold = KFold(n_splits=10, shuffle=True)\n",
    "# results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "# print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69643, (0.13653) with : {'mlp__batch_size': 5, 'mlp__epochs': 10}\n",
      "0.89286, (0.08907) with : {'mlp__batch_size': 5, 'mlp__epochs': 50}\n",
      "0.93750, (0.07039) with : {'mlp__batch_size': 5, 'mlp__epochs': 100}\n",
      "0.95536, (0.06074) with : {'mlp__batch_size': 5, 'mlp__epochs': 150}\n",
      "0.94643, (0.07244) with : {'mlp__batch_size': 5, 'mlp__epochs': 200}\n",
      "0.94643, (0.07244) with : {'mlp__batch_size': 5, 'mlp__epochs': 250}\n",
      "0.58929, (0.18485) with : {'mlp__batch_size': 10, 'mlp__epochs': 10}\n",
      "0.78571, (0.14248) with : {'mlp__batch_size': 10, 'mlp__epochs': 50}\n",
      "0.90179, (0.10019) with : {'mlp__batch_size': 10, 'mlp__epochs': 100}\n",
      "0.94643, (0.05963) with : {'mlp__batch_size': 10, 'mlp__epochs': 150}\n",
      "0.94643, (0.07244) with : {'mlp__batch_size': 10, 'mlp__epochs': 200}\n",
      "0.95536, (0.06074) with : {'mlp__batch_size': 10, 'mlp__epochs': 250}\n",
      "0.48214, (0.24759) with : {'mlp__batch_size': 20, 'mlp__epochs': 10}\n",
      "0.73214, (0.14856) with : {'mlp__batch_size': 20, 'mlp__epochs': 50}\n",
      "0.86607, (0.07394) with : {'mlp__batch_size': 20, 'mlp__epochs': 100}\n",
      "0.89286, (0.08907) with : {'mlp__batch_size': 20, 'mlp__epochs': 150}\n",
      "0.90179, (0.09173) with : {'mlp__batch_size': 20, 'mlp__epochs': 200}\n",
      "0.92857, (0.07913) with : {'mlp__batch_size': 20, 'mlp__epochs': 250}\n",
      "0.48214, (0.21686) with : {'mlp__batch_size': 40, 'mlp__epochs': 10}\n",
      "0.75893, (0.19442) with : {'mlp__batch_size': 40, 'mlp__epochs': 50}\n",
      "0.82143, (0.09142) with : {'mlp__batch_size': 40, 'mlp__epochs': 100}\n",
      "0.86607, (0.08176) with : {'mlp__batch_size': 40, 'mlp__epochs': 150}\n",
      "0.88393, (0.09999) with : {'mlp__batch_size': 40, 'mlp__epochs': 200}\n",
      "0.91964, (0.06346) with : {'mlp__batch_size': 40, 'mlp__epochs': 250}\n",
      "0.43750, (0.18723) with : {'mlp__batch_size': 60, 'mlp__epochs': 10}\n",
      "0.71429, (0.15011) with : {'mlp__batch_size': 60, 'mlp__epochs': 50}\n",
      "0.75893, (0.15752) with : {'mlp__batch_size': 60, 'mlp__epochs': 100}\n",
      "0.84821, (0.09780) with : {'mlp__batch_size': 60, 'mlp__epochs': 150}\n",
      "0.86607, (0.08420) with : {'mlp__batch_size': 60, 'mlp__epochs': 200}\n",
      "0.91071, (0.06986) with : {'mlp__batch_size': 60, 'mlp__epochs': 250}\n",
      "0.43750, (0.15697) with : {'mlp__batch_size': 80, 'mlp__epochs': 10}\n",
      "0.66964, (0.13070) with : {'mlp__batch_size': 80, 'mlp__epochs': 50}\n",
      "0.75893, (0.09152) with : {'mlp__batch_size': 80, 'mlp__epochs': 100}\n",
      "0.81250, (0.10763) with : {'mlp__batch_size': 80, 'mlp__epochs': 150}\n",
      "0.85714, (0.08070) with : {'mlp__batch_size': 80, 'mlp__epochs': 200}\n",
      "0.91071, (0.08106) with : {'mlp__batch_size': 80, 'mlp__epochs': 250}\n",
      "0.22321, (0.17551) with : {'mlp__batch_size': 100, 'mlp__epochs': 10}\n",
      "0.53571, (0.18375) with : {'mlp__batch_size': 100, 'mlp__epochs': 50}\n",
      "0.66071, (0.14716) with : {'mlp__batch_size': 100, 'mlp__epochs': 100}\n",
      "0.79464, (0.10896) with : {'mlp__batch_size': 100, 'mlp__epochs': 150}\n",
      "0.69643, (0.11173) with : {'mlp__batch_size': 100, 'mlp__epochs': 200}\n",
      "0.83036, (0.05039) with : {'mlp__batch_size': 100, 'mlp__epochs': 250}\n",
      "최적 스코어 : 0.9553571503077235, 사용한 파라미터 조합 : {'mlp__batch_size': 5, 'mlp__epochs': 150}\n"
     ]
    }
   ],
   "source": [
    "batch_size = [5,10,20,40,60,80,100]\n",
    "epochs=[10,50,100, 150, 200,250]\n",
    "param_grid = {'mlp__batch_size' : batch_size, 'mlp__epochs':epochs}\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "# results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "\n",
    "grid = GridSearchCV(estimator=pipeline, param_grid=param_grid,n_jobs=-1, cv=kfold)\n",
    "grid_result = grid.fit(X_train,Y_train)\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print('{:.5f}, ({:.5f}) with : {}'.format(mean, stdev, param))\n",
    "    \n",
    "print('최적 스코어 : {}, 사용한 파라미터 조합 : {}'.format(grid_result.best_score_,grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 93.79% (8.95%)\n"
     ]
    }
   ],
   "source": [
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp',KerasClassifier(build_fn=baseline_model, batch_size=5, epochs=150,verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "results = cross_val_score(pipeline, X_train, Y_train, cv=kfold)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardize',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('mlp',\n",
       "                 <keras.wrappers.scikit_learn.KerasClassifier object at 0x0000023762AF8EC8>)],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ = np.argmax(Y_test,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.equal(y_pred, y_pred_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ??????????????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
