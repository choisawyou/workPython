{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rimg2/pta91.jpg\n",
      "이미지 url :  http://10000img.com/rimg2/pta91.jpg\n",
      "rimg2/pta91.jpg\n",
      "이미지 url :  http://10000img.com/rimg2/pta91.jpg\n",
      "크롤링 종료\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from requests import get\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text, 'lxml')\n",
    "\n",
    "with open('image/'+filename, 'wb') as f:\n",
    "    f.write(image)\n",
    "\n",
    "def get(max_count=1):\n",
    "    base_url = 'http://10000img.com/'\n",
    "    url = 'http://10000img.com/ran.php'\n",
    "    \n",
    "    count = 1\n",
    "    \n",
    "    while count <= max_count:\n",
    "        img = soup.select('img')[0]['src']\n",
    "        img\n",
    "        img_url = base_url + img\n",
    "        image = requests.get(img_url).content\n",
    "        \n",
    "        \n",
    "        filename = os.path.basename(img_url)\n",
    "        \n",
    "        with open('image/'+filename, 'wb') as f:\n",
    "            f.write(image)\n",
    "        \n",
    "        print(img)\n",
    "        print('이미지 url : ',img_url)\n",
    "        count += 1\n",
    "    else : \n",
    "        print('크롤링 종료')\n",
    "        \n",
    "get(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Item no.: 1 --> Item name = styrofoam box\n",
      "Evaluating...\n",
      "Starting Download...\n",
      "\n",
      "\n",
      "Unfortunately all 100 could not be downloaded because some images were not downloadable. 0 is all we got for this search filter!\n",
      "\n",
      "Errors: 0\n",
      "\n",
      "({'styrofoam box': []}, 0)\n"
     ]
    }
   ],
   "source": [
    "from google_images_download import google_images_download as gd\n",
    "\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "def imageCrawling(keyword, dir):\n",
    "    reaponse = gd.googleimagesdownload()\n",
    "    \n",
    "    arguments = {'keywords': keyword,\n",
    "                'limit':100,\n",
    "                'print_urls':True,\n",
    "                'no_directory':True,\n",
    "                'output_directory' : dir}\n",
    "    paths = reaponse.download(arguments)\n",
    "    print(paths)\n",
    "    \n",
    "imageCrawling('styrofoam box','box/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "# search_term = '음료수 캔'\n",
    "# url = \"https://www.google.co.in/search?q=\" + search_term + \"&tbm=isch\"\n",
    "\n",
    "first_list = ['styrofoam']\n",
    "second_list = ['box', 'cup','board','png']\n",
    "\n",
    "for first in first_list:\n",
    "    for second in second_list:\n",
    "        new_query = first + \" \" + second\n",
    "        url = \"https://www.google.co.in/search?q=\" + new_query + \"&tbm=isch\"\n",
    "        browser = webdriver.Chrome('chromedriver.exe')\n",
    "        browser.get(url)\n",
    "        browser.implicitly_wait(10)\n",
    "\n",
    "# browser = webdriver.Chrome('chromedriver.exe')\n",
    "# browser.get(url)\n",
    "\n",
    "for i in range(200):\n",
    "    browser.implicitly_wait(10)\n",
    "    browser.execute_script('window.scrollBy(0,10000)')\n",
    "\n",
    "for idx, el in enumerate(browser.find_elements_by_class_name(\"rg_ic\")):\n",
    "    browser.implicitly_wait(10)\n",
    "    el.screenshot(str(idx) + \".jpg\")\n",
    "    \n",
    "browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "접속중\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 550/550 [00:05<00:00, 105.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수집완료\n",
      "폴더생성\n",
      "다운로드중\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "550it [08:10,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다운로드 완료\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# 키워드 입력\n",
    "keyword = \"스티로폼\"\n",
    "key = \"st\"\n",
    "\n",
    "\n",
    "\n",
    "# 웹접속 - 네이버 이미지 접속\n",
    "# 79.0.3945.36 / chrome version\n",
    "print(\"접속중\")\n",
    "driver = webdriver.Chrome(executable_path=\"./chromedriver.exe\")\n",
    "driver.implicitly_wait(30)\n",
    "\n",
    "url = 'https://search.naver.com/search.naver?where=image&sm=tab_jum&query={}'.format(keyword)\n",
    "driver.get(url)\n",
    "# 페이지 스크롤 다운\n",
    "body = driver.find_element_by_css_selector('body')\n",
    "for i in range(60):\n",
    "    body.send_keys(Keys.PAGE_DOWN)\n",
    "    time.sleep(1)\n",
    "\n",
    "# 이미지 링크 수집\n",
    "imgs = driver.find_elements_by_css_selector('img._img')\n",
    "result = []\n",
    "for img in tqdm(imgs):\n",
    "    if 'http' in img.get_attribute('src'):\n",
    "        result.append(img.get_attribute('src'))\n",
    "# print(result)\n",
    "\n",
    "driver.close()\n",
    "print('수집완료')\n",
    "\n",
    "# 파일 저장\n",
    "import os\n",
    "if not os.path.isdir('./{}'.format(key)):\n",
    "    print('폴더생성')\n",
    "    os.mkdir('./{}'.format(key))\n",
    "\n",
    "# 다운로드\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "print(\"다운로드중\")\n",
    "for index, link in tqdm(enumerate(result)):\n",
    "    start = link.rfind('.')\n",
    "    end = link.rfind('&')\n",
    "    # print(link[start:end])\n",
    "    filetype = link[start:end]\n",
    "    if filetype == '.jpg':  # jpg 만 다운\n",
    "        urlretrieve(link, './{}/{}{}{}'.format(key, key, index, filetype))\n",
    "        time.sleep(1)\n",
    "print(\"다운로드 완료\")\n",
    "\n",
    "# import zipfile\n",
    "# zip_file = zipfile.Zipfile('./{}.zip'.format(keyword),'w')\n",
    "# # 이 폴더안에 파일 가져오는거\n",
    "# for image in tqdm(os.listdir('./{}'.format(keyword))):\n",
    "#     zip_file.write('./{}/{}'.format(keyword,image), compress_type=zip_file.ZIP_DEFLATED)\n",
    "# zip_file.close()\n",
    "# print(\"압축완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import json\n",
    "import os\n",
    "import urllib.request\n",
    " \n",
    "#찾고자 하는 검색어를 url로 만들어 준다.\n",
    "searchterm = 'person'\n",
    "url = \"https://www.google.com/search?q=\"+searchterm+\"&source=lnms&tbm=isch\"\n",
    "# chrom webdriver 사용하여 브라우저를 가져온다.\n",
    "browser = webdriver.Chrome('./chromedriver/chromedriver')\n",
    "browser.get(url)\n",
    "\n",
    "# User-Agent를 통해 봇이 아닌 유저정보라는 것을 위해 사용\n",
    "header={'User-Agent':\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.134 Safari/537.36\"}\n",
    "# 이미지 카운트 (이미지 저장할 때 사용하기 위해서)\n",
    "counter = 0\n",
    "succounter = 0\n",
    " \n",
    "print(os.path)\n",
    "# 소스코드가 있는 경로에 '검색어' 폴더가 없으면 만들어준다.(이미지 저장 폴더를 위해서) \n",
    "if not os.path.exists(searchterm):\n",
    "    os.mkdir(searchterm)\n",
    " \n",
    "for _ in range(500):\n",
    "    # 가로 = 0, 세로 = 10000 픽셀 스크롤한다.\n",
    "    browser.execute_script(\"window.scrollBy(0,10000)\")\n",
    "    \n",
    "# div태그에서 class name이 rg_meta인 것을 찾아온다\n",
    "for x in browser.find_elements_by_xpath('//div[contains(@class,\"rg_meta\")]'):\n",
    "    counter = counter + 1\n",
    "    print (\"Total Count:\", counter)\n",
    "    print (\"Succsessful Count:\", succounter)\n",
    "    print (\"URL:\",json.loads(x.get_attribute('innerHTML'))[\"ou\"])\n",
    " \n",
    "    # 이미지 url\n",
    "    img = json.loads(x.get_attribute('innerHTML'))[\"ou\"]\n",
    "    # 이미지 확장자\n",
    "    imgtype = json.loads(x.get_attribute('innerHTML'))[\"ity\"]\n",
    "    \n",
    "    # 구글 이미지를 읽고 저장한다.\n",
    "    try:\n",
    "        req = urllib.request(img, headers={'User-Agent': header})\n",
    "        raw_img = urllib.request.urlopen(req).read()\n",
    "        File = open(os.path.join(searchterm , searchterm + \"_\" + str(counter) + \".\" + imgtype), \"wb\")\n",
    "        File.write(raw_img)\n",
    "        File.close()\n",
    "        succounter = succounter + 1\n",
    "    except:\n",
    "            print (\"can't get img\")\n",
    "            \n",
    "print (succounter, \"succesfully downloaded\")\n",
    "browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
